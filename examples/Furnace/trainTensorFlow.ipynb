{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import onnxruntime\n",
    "import tf2onnx\n",
    "\n",
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_name = [x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "\n",
    "The data can be found in CSV files `Furnace/data/eq_*.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_1215_df = pd.read_csv(\"Furnace/data/eq_1215.csv\")\n",
    "eq_1215_n_inputs = 14\n",
    "eq_1215_n_outputs = 18\n",
    "eq_1215_n_samples = len(eq_1215_df)\n",
    "\n",
    "assert eq_1215_n_inputs+eq_1215_n_outputs == len(eq_1215_df.columns), \"Sizes don't match\"\n",
    "\n",
    "eq_1215_input_names = eq_1215_df.columns[:eq_1215_n_inputs]\n",
    "eq_1215_output_names = eq_1215_df.columns[-eq_1215_n_outputs:]\n",
    "\n",
    "eq_1215_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_1215_train_inputs = np.array(eq_1215_df[eq_1215_input_names])\n",
    "eq_1215_train_outputs = np.array(eq_1215_df[eq_1215_output_names])\n",
    "\n",
    "display(eq_1215_train_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "In Julia we used a model like:\n",
    "\n",
    "```julia\n",
    "  model = Flux.Chain(Flux.Dense(nInputs,     nInputs*10,  Flux.Ïƒ),\n",
    "                     Flux.Dense(nInputs*10,  nOutputs*10, tanh),\n",
    "                     Flux.Dense(nOutputs*10, nOutputs))\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_1215_model = tf.keras.models.Sequential([\n",
    "  layers.Dense(eq_1215_n_inputs, activation='sigmoid'),\n",
    "  layers.Dense(eq_1215_n_inputs*10, activation='tanh'),\n",
    "  layers.Dense(eq_1215_n_outputs)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_1215_model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                      optimizer = tf.keras.optimizers.Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eq_1215_model.fit(eq_1215_train_inputs, eq_1215_train_outputs, epochs=10)\n",
    "#eq_1215_model.save(os.path.join(\"onnx\", \"eq_1215\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to ONNX\n",
    "\n",
    "Use `onnxruntime-gpu` and `tf2onnx` to export model to ONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec = (tf.TensorSpec((None, eq_1215_n_inputs,), tf.float32, name=\"input\"),)\n",
    "output_path = os.path.join(\"Furnace\", \"onnx\", \"eq_1215.onnx\")\n",
    "\n",
    "model_proto, _ = tf2onnx.convert.from_keras(eq_1215_model, input_signature=spec, opset=12, output_path=output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNInput(eq):\n",
    "  if eq == \"1215\":\n",
    "    return 14\n",
    "  elif eq == \"1585\":\n",
    "    return 20\n",
    "  elif eq == \"1933\":\n",
    "    return 20\n",
    "  else:\n",
    "    raise(IndexError('Not allowed eq value ' + eq))\n",
    "\n",
    "for eq in [\"1585\", \"1933\"]:\n",
    "  eq_df = pd.read_csv(\"Furnace/data/eq_\"+eq+\".csv\")\n",
    "  eq_n_inputs = getNInput(eq)\n",
    "  eq_n_outputs = len(eq_df.columns)-eq_n_inputs\n",
    "\n",
    "  eq_input_names = eq_df.columns[:eq_n_inputs]\n",
    "  eq_output_names = eq_df.columns[eq_n_inputs:]\n",
    "\n",
    "  eq_train_inputs = np.array(eq_df[eq_input_names])\n",
    "  eq_train_outputs = np.array(eq_df[eq_output_names])\n",
    "\n",
    "  model = tf.keras.models.Sequential([\n",
    "    layers.Dense(eq_n_inputs, activation='sigmoid'),\n",
    "    layers.Dense(eq_n_inputs*10, activation='tanh'),\n",
    "    layers.Dense(eq_n_outputs)\n",
    "  ])\n",
    "  model.compile(loss = tf.keras.losses.MeanSquaredError(),\n",
    "                optimizer = tf.keras.optimizers.Adam())\n",
    "  model.fit(eq_train_inputs, eq_train_outputs, epochs=10)\n",
    "  #model.save(os.path.join(\"onnx\", \"eq_\"+eq))\n",
    "\n",
    "  spec = (tf.TensorSpec((None, eq_n_inputs,), tf.float32, name=\"input\"),)\n",
    "  output_path = os.path.join(\"Furnace\", \"onnx\", \"eq_\"+eq+\".onnx\")\n",
    "  model_proto, _ = tf2onnx.convert.from_keras(model, input_signature=spec, opset=12, output_path=output_path)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
